---
title: "Cross validation"
---

```{r packages}
library(tidyverse) ## load filter(), ... function
library(blockCV)
library(sf)
library(raster)
library(ggplot2)
library(shiny) ## what for ... ??
library(ROSE)
library(caret)
source("functions.R")
library(randomForest)
```
To knit "by hand", `rmarkdown::render("Cross_validation.Rmd")`
```{r input_data}
## increase memory
if (.Platform$OS.type=="windows") memory.limit(1000000)

## get all data (as tables of x,y, predictors, change)
load("rr_points14.RData")

## test with smaller data set
dat <- dplyr::filter(rr_points14[["2014"]],
                     x<604000 & y >284000 &  y < 2846000)
dat$change2 <- change_fun(dat$change)
```

```{r upsample}
dat_gain <- dplyr::filter(dat, change2 %in% c("no gain", "gain")) 

## analyzing gain only, first ...
if (file.exists("dat_upsample")) {
    load("dat_upsample")
}  else {
    dat_upsample <- ROSE::ovun.sample(change ~ ., data = dat_gain, method = "both", N=1500)$data
}
```

```{r classified_maps}
Classified1=raster("Classified1.tif")
Classified2=raster("classified2.tif")
```
The appropriate format of species data for the blockCV package is simple features (sf) or SpatialPointsDataFrame.pamake a SpatialPointsDataFrame object from data.frame
```{r numeric_data}
PA_data <- st_as_sf(dat_upsample, coords = c("x", "y"), crs = crs(Classified1))
```

```{r train_vs_test}
set.seed(23489)
train_index <- sample(1:nrow(PA_data), 0.9 * nrow(dat_upsample))
sample_train <- PA_data[train_index, ]
sample_test  <- PA_data[-train_index, ]
```
Spatial blocking by specified range with random assignment
creates spatially separated folds based on a pre-specified distance (cell size of the blocks).
```{r spatial_blocking, cache=TRUE}
sb <- spatialBlock(speciesData = PA_data,
                   species = "change2",
                   rasterLayer = Classified1,
                   ## theRange = 70000, # size of the blocks
                   theRange = 5000, # size of the blocks                   
                   k = 5,
                   selection = "random",
                   iteration = 100, # find evenly dispersed folds
                   biomod2Format = TRUE,
                   xOffset = 0, # shift the blocks horizontally
                   yOffset = 0)
## select *first* (training) set of indices for each fold
## IS THIS THE RIGHT WAY TO DO THIS ???
trainfoldsb <- lapply(sb$folds, function(x) x[[1]])
traincontrolsb <- caret::trainControl(index = trainfoldsb,method="CV")
```
specify sets of similar environmental conditions based on the input covariates. Species data corresponding to any of these groups or clusters are assigned to a fold.
```{r envBlock}
eb <- envBlock(rasterLayer = Classified1,
               speciesData = PA_data,
               species = "change2",
               k = 5,
               standardization = "standard", # rescale variables between 0 and 1
               rasterBlock = FALSE,
               numLimit = 50)
trainfoldeb <- lapply(eb$folds, function(x) x[[1]])
traincontrolsb <- caret::trainControl(index = trainfoldeb,method="CV")
```
generates spatially separated training and testing folds by considering buffers of specified distance around each observation point. 
```{r biffering}
bf <- buffering(speciesData = PA_data,
                  theRange = 700,#ideally the range of spatial autocorrelation
                  species = "change2", # to count the number of presences and absences/backgrounds
                  spDataType = "PA", # presence-absence  data type
                  progress = TRUE)
# extract the folds (list)SpatialBlock object 
folds <- bf$folds

for(k in seq_len(length(folds))){
  # extracting the training and testing indices
  # this way works with folds list (but not foldID)
  trainSet <- unlist(folds[[k]][1]) # training set indices
  testSet <- unlist(folds[[k]][2])} # testing set indices
a=PA_data[trainSet,]
a$geometry <- NULL
b=PA_data[testSet, ]
b$geometry <- NULL
rfcv <- randomForest(formula= factor(change2) ~ .  - landuse - change,
                       data = a, n.trees=250,interaction.depth=7,
                       ## do.trace=1,
                       type="classification", proximity=TRUE) # model fitting on training set
predcv<- predict(rfcv, newdata=b, type = "prob")
head(predcv)
```
h-p:Idont know that why my parametres are not correct
```{r roc}
rocCurve<- pROC::roc(b$change2,predcv[,"change"])
plot(rocCurve ,col=c(4))
###calculate the area under curve (bigger is better)
auc(rocCurve)
```
may be this method is not coorect for cross validation
```{r random_forest_sbfolds}
rf_sb=train(as.factor(change2) ~ .,
              data = dat_upsample, ## use the same data here as we used in spatialBlock()?
              method = "ranger",
              trControl = traincontrolsb)

rf_predsb <- predict(rf_sb, sample_test)
consb=confusionMatrix(rf_predsb, as.factor(sample_test$change2))
```
hP=index` should be lists of integers.
adding points on saptialBlock plot
```{r random_forest_ebfolds}
rf_eb=train(as.factor(change2) ~ .,
              data = dat_upsample, ## use the same data here as we used in spatialBlock()?
              method = "ranger",
              trControl = traincontroleb)

rf_predeb <- predict(rf_eb, sample_test)
coneb=confusionMatrix(rf_predeb, as.factor(sample_test$change2))
```

```{r plot}
sb$plots + geom_sf(data = PA_data, alpha = 0.5)
```
visualising the generated folds on a map
```{r folds_in_spatialk}
fold=foldExplorer(eb, Classified1, PA_data)
print(fold)
```

