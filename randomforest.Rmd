---
title: "random forests"
author: "Hasti"
---

You can type regular text, explanations, etc. outside of "code chunks"


```{r pkgs}
library(ROSE)
library(spdep)
library(tidyverse)
library(caTools)
library(ranger)
library(caret)
```

```{r get_data}
## get all data (as tables of x,y, predictors, change)
load("rr_points14.RData")

## test with smaller data set
dat <- filter(rr_points14[["2014"]],
                  x<604000 & y >284000 &  y < 2846000)
```

For some analyses we have to reduce the response to binary

previously: split into two separate data sets
here we lump "gain" and "loss" together into "change" ...
advantage: we only have to run one analysis (not two separate analyses, one
for gain/no gain and one for loss/no loss
disadvantage: it might not make geological sense to lump (variables leading to dune loss)
together with (variables leading to dune gain)

```{r}
dat$change <- factor(dat$change, levels=0:3,
                     labels= c("no gain","gain","loss","no loss"))

## choice 1.
dat$change2 <- factor(ifelse(dat$change %in% c("no gain", "no loss"),
                                 "no change", "change"))

## choice 2.
dat_gain <- filter(dat, change %in% c("no gain", "gain")) 
dat_loss <- filter(dat, change %in% c("no loss", "loss"))

## analyzing gain only, first ...
dat_upsample <- ovun.sample(change ~ ., data = dat_gain, method = "both", N=1500)$data

set.seed(123)
## pkgname::function()
## explicitly note which package a function comes from ...
sample <- caTools::sample.split(dat_upsample$change2, SplitRatio = 0.75)

##subset=take random samples from a dataset
train <- subset(dat_upsample, sample == TRUE)
test <- subset(dat_upsample, sample == FALSE)

## a shorter way to do the same thing ...
## train <- subset(dat_upsample, sample)
## test  <- subset(dat_upsample,  !sample) ## ! means 'not'

## use all data ...
rf_fit <- train(as.factor(change2) ~ ., data = dat_upsample,
                method = "ranger")

## use only training data ...
rf_fit2 <- ranger(change2 ~ .,
                  data = train, num.trees = 500,
                  mtry = 6, importance = "impurity",
                  min.node.size = 3, replace = TRUE, num.threads = 3)
```
